04/14/2020 20:48:38 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
04/14/2020 20:48:38 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/fs45/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685
04/14/2020 20:48:38 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "_num_labels": 2,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "early_stopping": false,
  "eos_token_ids": null,
  "finetuning_task": "blimptask",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30522
}

04/14/2020 20:48:38 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/fs45/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
04/14/2020 20:48:38 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/fs45/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
04/14/2020 20:48:41 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
04/14/2020 20:48:41 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
04/14/2020 20:48:43 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='/scratch/fs45/nlu/data/blimp/data/blimptask', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=3.0, output_dir='/scratch/fs45/nlu/blimptask_run/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, save_steps=500, seed=42, server_ip='', server_port='', task_name='blimptask', tokenizer_name='', warmup_steps=0, weight_decay=0.0)
04/14/2020 20:48:43 - INFO - transformers.tokenization_utils -   Model name '/scratch/fs45/nlu/blimptask_run/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/scratch/fs45/nlu/blimptask_run/' is a path, a model identifier, or url to a directory containing tokenizer files.
04/14/2020 20:48:43 - INFO - transformers.tokenization_utils -   Didn't find file /scratch/fs45/nlu/blimptask_run/added_tokens.json. We won't load it.
04/14/2020 20:48:43 - INFO - transformers.tokenization_utils -   loading file /scratch/fs45/nlu/blimptask_run/vocab.txt
04/14/2020 20:48:43 - INFO - transformers.tokenization_utils -   loading file None
04/14/2020 20:48:43 - INFO - transformers.tokenization_utils -   loading file /scratch/fs45/nlu/blimptask_run/special_tokens_map.json
04/14/2020 20:48:43 - INFO - transformers.tokenization_utils -   loading file /scratch/fs45/nlu/blimptask_run/tokenizer_config.json
04/14/2020 20:48:43 - INFO - __main__ -   Evaluate the following checkpoints: ['/scratch/fs45/nlu/blimptask_run/']
04/14/2020 20:48:43 - INFO - transformers.configuration_utils -   loading configuration file /scratch/fs45/nlu/blimptask_run/config.json
04/14/2020 20:48:43 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "_num_labels": 2,
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "do_sample": false,
  "early_stopping": false,
  "eos_token_ids": null,
  "finetuning_task": "blimptask",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30522
}

04/14/2020 20:48:43 - INFO - transformers.modeling_utils -   loading weights file /scratch/fs45/nlu/blimptask_run/pytorch_model.bin
04/14/2020 20:48:46 - INFO - __main__ -   Creating features from dataset file at /scratch/fs45/nlu/data/blimp/data/blimptask
04/14/2020 20:48:46 - INFO - __main__ -   label list: 
04/14/2020 20:48:46 - INFO - __main__ -   ['0', '1']
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   Writing example 0/10000
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   *** Example ***
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   guid: dev-1
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   input_ids: 101 100 14091 2040 1037 2843 1997 6368 2008 2020 11228 2075 2116 2111 17612 2055 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   *** Example ***
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   guid: dev-2
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   input_ids: 101 100 14091 2008 1037 2843 1997 6368 2008 2020 11228 2075 2116 2111 17612 2055 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   *** Example ***
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   guid: dev-3
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   input_ids: 101 100 2106 2424 2041 2054 2296 5356 3771 2008 2323 1050 1005 1056 4392 5078 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   *** Example ***
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   guid: dev-4
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   input_ids: 101 100 2106 2424 2041 2008 2296 5356 3771 2008 2323 1050 1005 1056 4392 5078 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   *** Example ***
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   guid: dev-5
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   input_ids: 101 100 100 2031 1050 1005 1056 6618 2041 2054 18149 2015 2008 2031 17733 100 2298 2066 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/14/2020 20:48:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
04/14/2020 20:48:48 - INFO - __main__ -   Saving features into cached file /scratch/fs45/nlu/data/blimp/data/blimptask/cached_dev_bert-base-uncased_128_blimptask
04/14/2020 20:48:50 - INFO - __main__ -   ***** Running evaluation  *****
04/14/2020 20:48:50 - INFO - __main__ -     Num examples = 10000
04/14/2020 20:48:50 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/1250 [00:00<?, ?it/s]Evaluating:   0%|          | 1/1250 [00:00<05:08,  4.05it/s]Evaluating:   0%|          | 6/1250 [00:00<03:42,  5.58it/s]Evaluating:   1%|          | 11/1250 [00:00<02:43,  7.60it/s]Evaluating:   1%|▏         | 16/1250 [00:00<02:01, 10.18it/s]Evaluating:   2%|▏         | 21/1250 [00:00<01:32, 13.36it/s]Evaluating:   2%|▏         | 26/1250 [00:00<01:11, 17.10it/s]Evaluating:   2%|▏         | 31/1250 [00:00<00:57, 21.28it/s]Evaluating:   3%|▎         | 36/1250 [00:00<00:47, 25.68it/s]Evaluating:   3%|▎         | 41/1250 [00:01<00:40, 29.98it/s]Evaluating:   4%|▎         | 46/1250 [00:01<00:35, 33.99it/s]Evaluating:   4%|▍         | 51/1250 [00:01<00:31, 37.52it/s]Evaluating:   4%|▍         | 56/1250 [00:01<00:29, 40.41it/s]Evaluating:   5%|▍         | 61/1250 [00:01<00:27, 42.81it/s]Evaluating:   5%|▌         | 66/1250 [00:01<00:26, 44.64it/s]Evaluating:   6%|▌         | 71/1250 [00:01<00:25, 46.00it/s]Evaluating:   6%|▌         | 76/1250 [00:01<00:24, 46.98it/s]Evaluating:   6%|▋         | 81/1250 [00:01<00:24, 47.68it/s]Evaluating:   7%|▋         | 86/1250 [00:01<00:24, 48.22it/s]Evaluating:   7%|▋         | 91/1250 [00:02<00:23, 48.66it/s]Evaluating:   8%|▊         | 96/1250 [00:02<00:23, 48.92it/s]Evaluating:   8%|▊         | 101/1250 [00:02<00:23, 49.12it/s]Evaluating:   8%|▊         | 106/1250 [00:02<00:23, 49.19it/s]Evaluating:   9%|▉         | 111/1250 [00:02<00:23, 49.36it/s]Evaluating:   9%|▉         | 116/1250 [00:02<00:22, 49.47it/s]Evaluating:  10%|▉         | 121/1250 [00:02<00:22, 49.50it/s]Evaluating:  10%|█         | 126/1250 [00:02<00:22, 49.54it/s]Evaluating:  10%|█         | 131/1250 [00:02<00:22, 49.52it/s]Evaluating:  11%|█         | 136/1250 [00:02<00:22, 49.44it/s]Evaluating:  11%|█▏        | 141/1250 [00:03<00:22, 49.40it/s]Evaluating:  12%|█▏        | 146/1250 [00:03<00:22, 49.34it/s]Evaluating:  12%|█▏        | 151/1250 [00:03<00:22, 49.33it/s]Evaluating:  12%|█▏        | 156/1250 [00:03<00:22, 49.26it/s]Evaluating:  13%|█▎        | 161/1250 [00:03<00:22, 49.28it/s]Evaluating:  13%|█▎        | 166/1250 [00:03<00:21, 49.30it/s]Evaluating:  14%|█▎        | 171/1250 [00:03<00:21, 49.31it/s]Evaluating:  14%|█▍        | 176/1250 [00:03<00:21, 49.29it/s]Evaluating:  14%|█▍        | 181/1250 [00:03<00:21, 49.35it/s]Evaluating:  15%|█▍        | 186/1250 [00:03<00:21, 49.38it/s]Evaluating:  15%|█▌        | 191/1250 [00:04<00:21, 49.36it/s]Evaluating:  16%|█▌        | 196/1250 [00:04<00:21, 49.37it/s]Evaluating:  16%|█▌        | 201/1250 [00:04<00:21, 49.41it/s]Evaluating:  16%|█▋        | 206/1250 [00:04<00:21, 49.36it/s]Evaluating:  17%|█▋        | 211/1250 [00:04<00:21, 49.43it/s]Evaluating:  17%|█▋        | 216/1250 [00:04<00:20, 49.42it/s]Evaluating:  18%|█▊        | 221/1250 [00:04<00:20, 49.45it/s]Evaluating:  18%|█▊        | 226/1250 [00:04<00:20, 49.48it/s]Evaluating:  18%|█▊        | 231/1250 [00:04<00:20, 49.52it/s]Evaluating:  19%|█▉        | 236/1250 [00:05<00:20, 49.55it/s]Evaluating:  19%|█▉        | 241/1250 [00:05<00:20, 49.57it/s]Evaluating:  20%|█▉        | 246/1250 [00:05<00:20, 49.58it/s]Evaluating:  20%|██        | 251/1250 [00:05<00:20, 49.49it/s]Evaluating:  20%|██        | 256/1250 [00:05<00:20, 49.55it/s]Evaluating:  21%|██        | 261/1250 [00:05<00:19, 49.47it/s]Evaluating:  21%|██▏       | 266/1250 [00:05<00:19, 49.40it/s]Evaluating:  22%|██▏       | 271/1250 [00:05<00:19, 49.34it/s]Evaluating:  22%|██▏       | 276/1250 [00:05<00:19, 49.36it/s]Evaluating:  22%|██▏       | 281/1250 [00:05<00:19, 49.34it/s]Evaluating:  23%|██▎       | 286/1250 [00:06<00:19, 49.38it/s]Evaluating:  23%|██▎       | 291/1250 [00:06<00:19, 49.34it/s]Evaluating:  24%|██▎       | 296/1250 [00:06<00:19, 49.30it/s]Evaluating:  24%|██▍       | 301/1250 [00:06<00:19, 49.16it/s]Evaluating:  24%|██▍       | 306/1250 [00:06<00:19, 49.26it/s]Evaluating:  25%|██▍       | 311/1250 [00:06<00:19, 49.38it/s]Evaluating:  25%|██▌       | 316/1250 [00:06<00:18, 49.43it/s]Evaluating:  26%|██▌       | 321/1250 [00:06<00:18, 49.48it/s]Evaluating:  26%|██▌       | 326/1250 [00:06<00:18, 49.50it/s]Evaluating:  26%|██▋       | 331/1250 [00:06<00:18, 49.50it/s]Evaluating:  27%|██▋       | 336/1250 [00:07<00:18, 49.52it/s]Evaluating:  27%|██▋       | 341/1250 [00:07<00:18, 49.50it/s]Evaluating:  28%|██▊       | 346/1250 [00:07<00:18, 49.50it/s]Evaluating:  28%|██▊       | 351/1250 [00:07<00:18, 49.42it/s]Evaluating:  28%|██▊       | 356/1250 [00:07<00:18, 49.45it/s]Evaluating:  29%|██▉       | 361/1250 [00:07<00:17, 49.40it/s]Evaluating:  29%|██▉       | 366/1250 [00:07<00:17, 49.35it/s]Evaluating:  30%|██▉       | 371/1250 [00:07<00:17, 49.27it/s]Evaluating:  30%|███       | 376/1250 [00:07<00:17, 49.25it/s]Evaluating:  30%|███       | 381/1250 [00:07<00:17, 49.18it/s]Evaluating:  31%|███       | 386/1250 [00:08<00:17, 49.18it/s]Evaluating:  31%|███▏      | 391/1250 [00:08<00:17, 49.14it/s]Evaluating:  32%|███▏      | 396/1250 [00:08<00:17, 49.14it/s]Evaluating:  32%|███▏      | 401/1250 [00:08<00:17, 49.06it/s]Evaluating:  32%|███▏      | 406/1250 [00:08<00:17, 49.14it/s]Evaluating:  33%|███▎      | 411/1250 [00:08<00:17, 49.21it/s]Evaluating:  33%|███▎      | 416/1250 [00:08<00:16, 49.26it/s]Evaluating:  34%|███▎      | 421/1250 [00:08<00:16, 49.28it/s]Evaluating:  34%|███▍      | 426/1250 [00:08<00:16, 49.27it/s]Evaluating:  34%|███▍      | 431/1250 [00:08<00:16, 49.30it/s]Evaluating:  35%|███▍      | 436/1250 [00:09<00:16, 49.39it/s]Evaluating:  35%|███▌      | 441/1250 [00:09<00:16, 49.39it/s]Evaluating:  36%|███▌      | 446/1250 [00:09<00:16, 49.37it/s]Evaluating:  36%|███▌      | 451/1250 [00:09<00:16, 49.31it/s]Evaluating:  36%|███▋      | 456/1250 [00:09<00:16, 49.33it/s]Evaluating:  37%|███▋      | 461/1250 [00:09<00:16, 49.31it/s]Evaluating:  37%|███▋      | 466/1250 [00:09<00:15, 49.37it/s]Evaluating:  38%|███▊      | 471/1250 [00:09<00:15, 49.39it/s]Evaluating:  38%|███▊      | 476/1250 [00:09<00:15, 49.44it/s]Evaluating:  38%|███▊      | 481/1250 [00:09<00:15, 49.35it/s]Evaluating:  39%|███▉      | 486/1250 [00:10<00:15, 49.32it/s]Evaluating:  39%|███▉      | 491/1250 [00:10<00:15, 49.31it/s]Evaluating:  40%|███▉      | 496/1250 [00:10<00:15, 49.24it/s]Evaluating:  40%|████      | 501/1250 [00:10<00:15, 49.04it/s]Evaluating:  40%|████      | 506/1250 [00:10<00:15, 49.02it/s]Evaluating:  41%|████      | 511/1250 [00:10<00:15, 49.08it/s]Evaluating:  41%|████▏     | 516/1250 [00:10<00:14, 49.17it/s]Evaluating:  42%|████▏     | 521/1250 [00:10<00:14, 49.23it/s]Evaluating:  42%|████▏     | 526/1250 [00:10<00:14, 49.30it/s]Evaluating:  42%|████▏     | 531/1250 [00:10<00:14, 49.39it/s]Evaluating:  43%|████▎     | 536/1250 [00:11<00:14, 49.38it/s]Evaluating:  43%|████▎     | 541/1250 [00:11<00:14, 49.38it/s]Evaluating:  44%|████▎     | 546/1250 [00:11<00:14, 49.41it/s]Evaluating:  44%|████▍     | 551/1250 [00:11<00:14, 49.21it/s]Evaluating:  44%|████▍     | 556/1250 [00:11<00:14, 49.17it/s]Evaluating:  45%|████▍     | 561/1250 [00:11<00:14, 49.16it/s]Evaluating:  45%|████▌     | 566/1250 [00:11<00:13, 49.19it/s]Evaluating:  46%|████▌     | 571/1250 [00:11<00:13, 49.15it/s]Evaluating:  46%|████▌     | 576/1250 [00:11<00:13, 49.14it/s]Evaluating:  46%|████▋     | 581/1250 [00:12<00:13, 49.15it/s]Evaluating:  47%|████▋     | 586/1250 [00:12<00:13, 49.15it/s]Evaluating:  47%|████▋     | 591/1250 [00:12<00:13, 49.18it/s]Evaluating:  48%|████▊     | 596/1250 [00:12<00:13, 49.12it/s]Evaluating:  48%|████▊     | 601/1250 [00:12<00:13, 49.03it/s]Evaluating:  48%|████▊     | 606/1250 [00:12<00:13, 49.09it/s]Evaluating:  49%|████▉     | 611/1250 [00:12<00:12, 49.18it/s]Evaluating:  49%|████▉     | 616/1250 [00:12<00:12, 49.25it/s]Evaluating:  50%|████▉     | 621/1250 [00:12<00:12, 49.21it/s]Evaluating:  50%|█████     | 626/1250 [00:12<00:12, 49.30it/s]Evaluating:  50%|█████     | 631/1250 [00:13<00:12, 49.32it/s]Evaluating:  51%|█████     | 636/1250 [00:13<00:12, 49.37it/s]Evaluating:  51%|█████▏    | 641/1250 [00:13<00:12, 49.39it/s]Evaluating:  52%|█████▏    | 646/1250 [00:13<00:12, 49.41it/s]Evaluating:  52%|█████▏    | 651/1250 [00:13<00:12, 49.18it/s]Evaluating:  52%|█████▏    | 656/1250 [00:13<00:12, 49.21it/s]Evaluating:  53%|█████▎    | 661/1250 [00:13<00:11, 49.22it/s]Evaluating:  53%|█████▎    | 666/1250 [00:13<00:11, 49.21it/s]Evaluating:  54%|█████▎    | 671/1250 [00:13<00:11, 49.15it/s]Evaluating:  54%|█████▍    | 676/1250 [00:13<00:11, 49.13it/s]Evaluating:  54%|█████▍    | 681/1250 [00:14<00:11, 49.17it/s]Evaluating:  55%|█████▍    | 686/1250 [00:14<00:11, 49.20it/s]Evaluating:  55%|█████▌    | 691/1250 [00:14<00:11, 49.27it/s]Evaluating:  56%|█████▌    | 696/1250 [00:14<00:11, 49.22it/s]Evaluating:  56%|█████▌    | 701/1250 [00:14<00:11, 49.28it/s]Evaluating:  56%|█████▋    | 706/1250 [00:14<00:11, 49.33it/s]Evaluating:  57%|█████▋    | 711/1250 [00:14<00:10, 49.42it/s]Evaluating:  57%|█████▋    | 716/1250 [00:14<00:10, 49.46it/s]Evaluating:  58%|█████▊    | 721/1250 [00:14<00:10, 49.47it/s]Evaluating:  58%|█████▊    | 726/1250 [00:14<00:10, 49.48it/s]Evaluating:  58%|█████▊    | 731/1250 [00:15<00:10, 49.50it/s]Evaluating:  59%|█████▉    | 736/1250 [00:15<00:10, 49.47it/s]Evaluating:  59%|█████▉    | 741/1250 [00:15<00:10, 49.42it/s]Evaluating:  60%|█████▉    | 746/1250 [00:15<00:10, 49.22it/s]Evaluating:  60%|██████    | 751/1250 [00:15<00:10, 49.18it/s]Evaluating:  60%|██████    | 756/1250 [00:15<00:10, 49.20it/s]Evaluating:  61%|██████    | 761/1250 [00:15<00:09, 49.20it/s]Evaluating:  61%|██████▏   | 766/1250 [00:15<00:09, 49.19it/s]Evaluating:  62%|██████▏   | 771/1250 [00:15<00:09, 49.22it/s]Evaluating:  62%|██████▏   | 776/1250 [00:15<00:09, 49.18it/s]Evaluating:  62%|██████▏   | 781/1250 [00:16<00:09, 49.22it/s]Evaluating:  63%|██████▎   | 786/1250 [00:16<00:09, 49.33it/s]Evaluating:  63%|██████▎   | 791/1250 [00:16<00:09, 49.38it/s]Evaluating:  64%|██████▎   | 796/1250 [00:16<00:09, 49.27it/s]Evaluating:  64%|██████▍   | 801/1250 [00:16<00:09, 49.31it/s]Evaluating:  64%|██████▍   | 806/1250 [00:16<00:08, 49.34it/s]Evaluating:  65%|██████▍   | 811/1250 [00:16<00:08, 49.35it/s]Evaluating:  65%|██████▌   | 816/1250 [00:16<00:08, 49.37it/s]Evaluating:  66%|██████▌   | 821/1250 [00:16<00:08, 49.32it/s]Evaluating:  66%|██████▌   | 826/1250 [00:16<00:08, 49.28it/s]Evaluating:  66%|██████▋   | 831/1250 [00:17<00:08, 49.24it/s]Evaluating:  67%|██████▋   | 836/1250 [00:17<00:08, 49.21it/s]Evaluating:  67%|██████▋   | 841/1250 [00:17<00:08, 49.16it/s]Evaluating:  68%|██████▊   | 846/1250 [00:17<00:08, 49.01it/s]Evaluating:  68%|██████▊   | 851/1250 [00:17<00:08, 48.98it/s]Evaluating:  68%|██████▊   | 856/1250 [00:17<00:08, 49.10it/s]Evaluating:  69%|██████▉   | 861/1250 [00:17<00:07, 49.14it/s]Evaluating:  69%|██████▉   | 866/1250 [00:17<00:07, 49.12it/s]Evaluating:  70%|██████▉   | 871/1250 [00:17<00:07, 49.15it/s]Evaluating:  70%|███████   | 876/1250 [00:17<00:07, 49.17it/s]Evaluating:  70%|███████   | 881/1250 [00:18<00:07, 49.20it/s]Evaluating:  71%|███████   | 886/1250 [00:18<00:07, 49.27it/s]Evaluating:  71%|███████▏  | 891/1250 [00:18<00:07, 49.36it/s]Evaluating:  72%|███████▏  | 896/1250 [00:18<00:07, 49.20it/s]Evaluating:  72%|███████▏  | 901/1250 [00:18<00:07, 49.16it/s]Evaluating:  72%|███████▏  | 906/1250 [00:18<00:06, 49.17it/s]Evaluating:  73%|███████▎  | 911/1250 [00:18<00:06, 49.19it/s]Evaluating:  73%|███████▎  | 916/1250 [00:18<00:06, 49.09it/s]Evaluating:  74%|███████▎  | 921/1250 [00:18<00:06, 49.07it/s]Evaluating:  74%|███████▍  | 926/1250 [00:19<00:06, 49.09it/s]Evaluating:  74%|███████▍  | 931/1250 [00:19<00:06, 49.15it/s]Evaluating:  75%|███████▍  | 936/1250 [00:19<00:06, 49.19it/s]Evaluating:  75%|███████▌  | 941/1250 [00:19<00:06, 49.17it/s]Evaluating:  76%|███████▌  | 946/1250 [00:19<00:06, 49.12it/s]Evaluating:  76%|███████▌  | 951/1250 [00:19<00:06, 49.16it/s]Evaluating:  76%|███████▋  | 956/1250 [00:19<00:05, 49.21it/s]Evaluating:  77%|███████▋  | 961/1250 [00:19<00:05, 49.29it/s]Evaluating:  77%|███████▋  | 966/1250 [00:19<00:05, 49.31it/s]Evaluating:  78%|███████▊  | 971/1250 [00:19<00:05, 49.16it/s]Evaluating:  78%|███████▊  | 976/1250 [00:20<00:05, 49.13it/s]Evaluating:  78%|███████▊  | 981/1250 [00:20<00:05, 49.15it/s]Evaluating:  79%|███████▉  | 986/1250 [00:20<00:05, 49.07it/s]Evaluating:  79%|███████▉  | 991/1250 [00:20<00:05, 49.06it/s]Evaluating:  80%|███████▉  | 996/1250 [00:20<00:05, 48.97it/s]Evaluating:  80%|████████  | 1001/1250 [00:20<00:05, 49.04it/s]Evaluating:  80%|████████  | 1006/1250 [00:20<00:04, 49.15it/s]Evaluating:  81%|████████  | 1011/1250 [00:20<00:04, 49.21it/s]Evaluating:  81%|████████▏ | 1016/1250 [00:20<00:04, 49.21it/s]Evaluating:  82%|████████▏ | 1021/1250 [00:20<00:04, 49.24it/s]Evaluating:  82%|████████▏ | 1026/1250 [00:21<00:04, 49.28it/s]Evaluating:  82%|████████▏ | 1031/1250 [00:21<00:04, 49.32it/s]Evaluating:  83%|████████▎ | 1036/1250 [00:21<00:04, 49.34it/s]Evaluating:  83%|████████▎ | 1041/1250 [00:21<00:04, 49.03it/s]Evaluating:  84%|████████▎ | 1046/1250 [00:21<00:04, 48.91it/s]Evaluating:  84%|████████▍ | 1051/1250 [00:21<00:04, 48.97it/s]Evaluating:  84%|████████▍ | 1056/1250 [00:21<00:03, 49.01it/s]Evaluating:  85%|████████▍ | 1061/1250 [00:21<00:03, 49.04it/s]Evaluating:  85%|████████▌ | 1066/1250 [00:21<00:03, 49.03it/s]Evaluating:  86%|████████▌ | 1071/1250 [00:21<00:03, 49.08it/s]Evaluating:  86%|████████▌ | 1076/1250 [00:22<00:03, 49.12it/s]Evaluating:  86%|████████▋ | 1081/1250 [00:22<00:03, 49.15it/s]Evaluating:  87%|████████▋ | 1086/1250 [00:22<00:03, 49.20it/s]Evaluating:  87%|████████▋ | 1091/1250 [00:22<00:03, 49.05it/s]Evaluating:  88%|████████▊ | 1096/1250 [00:22<00:03, 49.09it/s]Evaluating:  88%|████████▊ | 1101/1250 [00:22<00:03, 49.14it/s]Evaluating:  88%|████████▊ | 1106/1250 [00:22<00:02, 49.24it/s]Evaluating:  89%|████████▉ | 1111/1250 [00:22<00:02, 49.13it/s]Evaluating:  89%|████████▉ | 1116/1250 [00:22<00:02, 49.06it/s]Evaluating:  90%|████████▉ | 1121/1250 [00:22<00:02, 48.98it/s]Evaluating:  90%|█████████ | 1126/1250 [00:23<00:02, 48.89it/s]Evaluating:  90%|█████████ | 1131/1250 [00:23<00:02, 48.89it/s]Evaluating:  91%|█████████ | 1136/1250 [00:23<00:02, 48.90it/s]Evaluating:  91%|█████████▏| 1141/1250 [00:23<00:02, 48.82it/s]Evaluating:  92%|█████████▏| 1146/1250 [00:23<00:02, 48.88it/s]Evaluating:  92%|█████████▏| 1151/1250 [00:23<00:02, 48.99it/s]Evaluating:  92%|█████████▏| 1156/1250 [00:23<00:01, 49.08it/s]Evaluating:  93%|█████████▎| 1161/1250 [00:23<00:01, 49.07it/s]Evaluating:  93%|█████████▎| 1166/1250 [00:23<00:01, 49.06it/s]Evaluating:  94%|█████████▎| 1171/1250 [00:24<00:01, 48.98it/s]Evaluating:  94%|█████████▍| 1176/1250 [00:24<00:01, 49.00it/s]Evaluating:  94%|█████████▍| 1181/1250 [00:24<00:01, 48.96it/s]Evaluating:  95%|█████████▍| 1186/1250 [00:24<00:01, 48.94it/s]Evaluating:  95%|█████████▌| 1191/1250 [00:24<00:01, 48.88it/s]Evaluating:  96%|█████████▌| 1196/1250 [00:24<00:01, 48.95it/s]Evaluating:  96%|█████████▌| 1201/1250 [00:24<00:00, 49.07it/s]Evaluating:  96%|█████████▋| 1206/1250 [00:24<00:00, 49.17it/s]Evaluating:  97%|█████████▋| 1211/1250 [00:24<00:00, 49.17it/s]Evaluating:  97%|█████████▋| 1216/1250 [00:24<00:00, 49.23it/s]Evaluating:  98%|█████████▊| 1221/1250 [00:25<00:00, 49.26it/s]Evaluating:  98%|█████████▊| 1226/1250 [00:25<00:00, 49.29it/s]Evaluating:  98%|█████████▊| 1231/1250 [00:25<00:00, 49.31it/s]Evaluating:  99%|█████████▉| 1236/1250 [00:25<00:00, 49.30it/s]Evaluating:  99%|█████████▉| 1241/1250 [00:25<00:00, 49.16it/s]Evaluating: 100%|█████████▉| 1246/1250 [00:25<00:00, 49.02it/s]Evaluating: 100%|██████████| 1250/1250 [00:25<00:00, 48.80it/s]
04/14/2020 20:49:15 - INFO - __main__ -   preds: 
04/14/2020 20:49:15 - INFO - __main__ -   [1 0 1 ... 1 1 1]
04/14/2020 20:49:15 - INFO - __main__ -   labels: 
04/14/2020 20:49:15 - INFO - __main__ -   [1 0 1 ... 0 1 0]
04/14/2020 20:49:15 - INFO - __main__ -   ***** Eval results  *****
04/14/2020 20:49:15 - INFO - __main__ -     acc = 0.6622
Traceback (most recent call last):
  File "/scratch/fs45/nlu/code/transformers/examples/run_glue_test.py", line 706, in <module>
    main()
  File "/scratch/fs45/nlu/code/transformers/examples/run_glue_test.py", line 698, in main
    result = evaluate(args, model, tokenizer, prefix=prefix)
  File "/scratch/fs45/nlu/code/transformers/examples/run_glue_test.py", line 368, in evaluate
    writer.write(preds)
TypeError: write() argument must be str, not numpy.ndarray
